{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f4329d",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2475dd",
   "metadata": {
    "papermill": {
     "duration": 0.000641,
     "end_time": "2024-12-19T11:01:19.476857",
     "exception": false,
     "start_time": "2024-12-19T11:01:19.476216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modelado de los datos Fotovoltáico de OBREMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5381a213",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304282fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T11:01:19.483284Z",
     "iopub.status.busy": "2024-12-19T11:01:19.482501Z",
     "iopub.status.idle": "2024-12-19T11:01:20.207800Z",
     "shell.execute_reply": "2024-12-19T11:01:20.205254Z"
    },
    "papermill": {
     "duration": 0.904783,
     "end_time": "2024-12-19T11:01:20.383892",
     "exception": true,
     "start_time": "2024-12-19T11:01:19.479109",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymongo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Librerías necesarias\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MongoClient\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymongo'"
     ]
    }
   ],
   "source": [
    "# Librerías necesarias\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8602f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1) Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa88a7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('generation_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5ea82",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb52dc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2) EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b1920",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evolución de las variables a lo largo del tiempo\n",
    "df_plot = data.loc[:, \"DC_POWER\":]\n",
    "variables = df_plot.columns\n",
    "\n",
    "fig, axes = plt.subplots(14, 1, figsize=(20, 2 * 14))\n",
    "axes = axes.flatten()  \n",
    "\n",
    "df_plot['DATE_TIME'] = pd.to_datetime(data['DATE_TIME'])\n",
    "\n",
    "data_plant_1 = data[data['PLANT_ID'] == 4135001]\n",
    "data_plant_2 = data[data['PLANT_ID'] == 4136001]\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    e=i*2\n",
    "    axes[e].plot(data_plant_1['DATE_TIME'], data_plant_1[var], label='PLANT 1', color='blue')\n",
    "    axes[e].xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    axes[e].xaxis.set_major_formatter(mdates.DateFormatter('%b'))  \n",
    "    axes[e].tick_params(axis='x', rotation=45)\n",
    "    axes[e].set_ylabel(var)\n",
    "    axes[e].set_title(f\"Evolución de {var}\")\n",
    "    axes[e].legend()\n",
    "    \n",
    "    axes[e+1].plot(data_plant_2['DATE_TIME'], data_plant_2[var], label='PLANT 2', color='red')\n",
    "    axes[e+1].xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    axes[e+1].xaxis.set_major_formatter(mdates.DateFormatter('%b'))  \n",
    "    axes[e+1].tick_params(axis='x', rotation=45)\n",
    "    axes[e+1].set_ylabel(var)\n",
    "    axes[e+1].set_title(f\"Evolución de {var}\")\n",
    "    axes[e+1].legend()\n",
    "\n",
    "\n",
    "for j in range(e + 2, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ed90c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Histograma de las variables\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "df_plot = data.loc[:,\"DC_POWER\":]\n",
    "num_cols = len(df_plot.columns)\n",
    "\n",
    "fig, axes = plt.subplots(1, 7, figsize=(20, 5))\n",
    "axes = axes.flatten() \n",
    "heights = []\n",
    "\n",
    "for i, col in enumerate(df_plot.columns):\n",
    "    histogram = sns.histplot(df_plot[col], ax=axes[i], kde=True, stat=\"density\", bins=30)\n",
    "    heights.append(max([patch.get_height() for patch in histogram.patches]))\n",
    "    axes[i].set_title(f'{col}')\n",
    "    #axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Densidad')\n",
    "    \n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710870c3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mapas de correlaciones\n",
    "df_mat = data.loc[:, 'DC_POWER':]\n",
    "pearson = pd.DataFrame(index=df_mat.columns, columns=df_mat.columns)\n",
    "spearman = pd.DataFrame(index=df_mat.columns, columns=df_mat.columns)\n",
    "kendall = pd.DataFrame(index=df_mat.columns, columns=df_mat.columns)\n",
    "\n",
    "# Calcular correlaciones iterando sobre cada par de variables\n",
    "for i in range(len(df_mat.columns)):\n",
    "    for j in range(i, len(df_mat.columns)):\n",
    "        if i == j:\n",
    "            pass\n",
    "        else:\n",
    "            df_aux = df_mat.iloc[:, [i, j]].dropna()\n",
    "            if df_aux.iloc[:, 0].nunique() <= 1 or df_aux.iloc[:, 1].nunique() <= 1:\n",
    "                pass\n",
    "            else:\n",
    "                nulos = df_aux.isnull().sum().sum()\n",
    "                pearson.iloc[i, j] = df_aux.iloc[:, 0].corr(df_aux.iloc[:, 1], method='pearson')\n",
    "                spearman.iloc[i, j] = df_aux.iloc[:, 0].corr(df_aux.iloc[:, 1], method='spearman')\n",
    "                kendall.iloc[i, j] = df_aux.iloc[:, 0].corr(df_aux.iloc[:, 1], method='kendall')\n",
    "\n",
    "# Crear los plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.heatmap(pearson.astype(float), annot=True, cmap='RdBu', vmin=-1, vmax=1, ax=axes[0], cbar_kws={'label': 'Correlación'},\n",
    "            annot_kws={'size': 8})  \n",
    "axes[0].set_title('Correlación (Pearson)')\n",
    "\n",
    "sns.heatmap(spearman.astype(float), annot=True, cmap='RdBu', vmin=-1, vmax=1, ax=axes[1], cbar_kws={'label': 'Correlación'},\n",
    "            annot_kws={'size': 8}) \n",
    "axes[1].set_title('Correlación (Spearman)')\n",
    "\n",
    "sns.heatmap(kendall.astype(float), annot=True, cmap='RdBu', vmin=-1, vmax=1, ax=axes[2], cbar_kws={'label': 'Correlación'},\n",
    "            annot_kws={'size': 8}) \n",
    "axes[2].set_title('Correlación (Kendall)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd48584",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3) Métodos Soft-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b86008",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, learning_curve\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a67d55",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "df = data.loc[:,['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION', 'AC_POWER']]\n",
    "\n",
    "# Estadarozación del conjunto de datos\n",
    "scaler = StandardScaler()\n",
    "data_estandarizada = scaler.fit_transform(df)\n",
    "\n",
    "predictors = df.loc[:,['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']]\n",
    "objective = df['AC_POWER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf4d59",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separación de datos para la modelización\n",
    "X, X_val, y, y_val = train_test_split(predictors, objective, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2754f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 3.1) AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f65559",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diferentes implementaciones de AdaBoostRegressor\n",
    "# Validación cruzada AdaBoostRegressor\n",
    "abr = AdaBoostRegressor(learning_rate=0.05, n_estimators=200)\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "r2_cv = cross_val_score(abr, X, y, cv=cv, scoring='r2')\n",
    "mse_cv = cross_val_score(abr, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "mae_cv = cross_val_score(abr, X, y, cv=cv, scoring='neg_mean_absolute_error')\n",
    "\n",
    "mse_cv = -mse_cv\n",
    "mae_cv = -mae_cv\n",
    "\n",
    "r2_mean = np.mean(r2_cv)\n",
    "mse_mean = np.mean(mse_cv)\n",
    "rmse_mean = np.sqrt(mse_mean)\n",
    "mae_mean = np.mean(mae_cv)\n",
    "\n",
    "resultados_cv = {\n",
    "    'R² promedio (CV)': float(r2_mean),\n",
    "    'MSE promedio (CV)': float(mse_mean),\n",
    "    'RMSE promedio (CV)': float(rmse_mean),\n",
    "    'MAE promedio (CV)': float(mae_mean)\n",
    "}\n",
    "\n",
    "print(\"Resultados de validación cruzada:\")\n",
    "print(resultados_cv)\n",
    "\n",
    "# Para mostrar las curvas de aprendizaje\n",
    "abr = AdaBoostRegressor(learning_rate=0.05, n_estimators=200)\n",
    "\n",
    "train_sizes_mse, train_scores_mse, test_scores_mse = learning_curve(abr, X, y, cv=cv, scoring='neg_mean_squared_error', train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "train_sizes_r2, train_scores_r2, test_scores_r2 = learning_curve(abr, X, y, cv=cv, scoring='r2', train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "train_scores_mean_mse = -np.mean(train_scores_mse, axis=1)\n",
    "train_scores_std_mse = np.std(train_scores_mse, axis=1)\n",
    "test_scores_mean_mse = -np.mean(test_scores_mse, axis=1)\n",
    "test_scores_std_mse = np.std(test_scores_mse, axis=1)\n",
    "train_scores_mean_r2 = np.mean(train_scores_r2, axis=1)\n",
    "train_scores_std_r2 = np.std(train_scores_r2, axis=1)\n",
    "test_scores_mean_r2 = np.mean(test_scores_r2, axis=1)\n",
    "test_scores_std_r2 = np.std(test_scores_r2, axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].fill_between(train_sizes_mse, train_scores_mean_mse - train_scores_std_mse, train_scores_mean_mse + train_scores_std_mse, alpha=0.1, color=\"r\")\n",
    "axs[0].fill_between(train_sizes_mse, test_scores_mean_mse - test_scores_std_mse, test_scores_mean_mse + test_scores_std_mse, alpha=0.1, color=\"g\")\n",
    "axs[0].plot(train_sizes_mse, train_scores_mean_mse, 'o-', color=\"r\", label=\"Puntaje de entrenamiento\")\n",
    "axs[0].plot(train_sizes_mse, test_scores_mean_mse, 'o-', color=\"g\", label=\"Puntaje de validación\")\n",
    "axs[0].set_xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "axs[0].set_ylabel(\"Error cuadrático medio\")\n",
    "axs[0].set_title(\"Curvas de aprendizaje MSE (SVR)\")\n",
    "axs[0].legend(loc=\"best\")\n",
    "\n",
    "axs[1].fill_between(train_sizes_r2, train_scores_mean_r2 - train_scores_std_r2, train_scores_mean_r2 + train_scores_std_r2, alpha=0.1, color=\"r\")\n",
    "axs[1].fill_between(train_sizes_r2, test_scores_mean_r2 - test_scores_std_r2, test_scores_mean_r2 + test_scores_std_r2, alpha=0.1, color=\"g\")\n",
    "axs[1].plot(train_sizes_r2, train_scores_mean_r2, 'o-', color=\"r\", label=\"Puntaje de entrenamiento\")\n",
    "axs[1].plot(train_sizes_r2, test_scores_mean_r2, 'o-', color=\"g\", label=\"Puntaje de validación\")\n",
    "axs[1].set_xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "axs[1].set_ylabel(\"Error cuadrático medio\")\n",
    "axs[1].set_title(\"Curvas de aprendizaje R2 (SVR)\")\n",
    "axs[1].legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Para validación sobre datos nuevos\n",
    "abr = AdaBoostRegressor(learning_rate=0.05, n_estimators=200)\n",
    "abr.fit(X, y)\n",
    "y_pred = abr.predict(X_val) \n",
    "\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred) \n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "resultados = {\n",
    "    'R²': float(r2),\n",
    "    'MSE': float(mse),\n",
    "    'RMSE': float(rmse),\n",
    "    'MAE': float(mae)\n",
    "}\n",
    "print(\"Resultados de validación global:\")\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa05dff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4) Entrenamiento del modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8eae15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 4.1) Prueba sobre datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15974bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se prueba primero sobre el conjunto de validación\n",
    "abr = AdaBoostRegressor(learning_rate=0.05, n_estimators=200)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a44700",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "abr.fit(X, y)\n",
    "y_pred = abr.predict(X_val) \n",
    "\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred) \n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "resultados = {\n",
    "    'R²': float(r2),\n",
    "    'MSE': float(mse),\n",
    "    'RMSE': float(rmse),\n",
    "    'MAE': float(mae)\n",
    "}\n",
    "\n",
    "print(resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d60dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 4.2) Entrenamiento final del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b95c9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "abr.fit(predictors, objective)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DATAMITE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.712216,
   "end_time": "2024-12-19T11:01:21.718808",
   "environment_variables": {},
   "exception": true,
   "input_path": "modelización_fotovoltaico.ipynb",
   "output_path": "-",
   "parameters": {},
   "start_time": "2024-12-19T11:01:10.006592",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}